{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44af7f84",
   "metadata": {},
   "source": [
    "# Document RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f709822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import all the dependencies\n",
    "from qdrant_client import models, QdrantClient\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import PromptTemplate\n",
    "from peft import PeftModel, PeftConfig\n",
    "#\n",
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "#\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2177168f",
   "metadata": {},
   "source": [
    "## Initialise the Document Store\n",
    "You will need to customise this section to your specific use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5bb99d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the document that you need to parse, please change the location to where the pdf resides\n",
    "\n",
    "# Load 1 PDF file\n",
    "# loader = PyPDFLoader(\"/mnt/data/smuckers_poc/RAG/2024-First-Quarter-Results.pdf\")\n",
    "# or load an entire folder\n",
    "loader = PyPDFDirectoryLoader(\"/mnt/data/\" + os.environ['DOMINO_PROJECT_NAME'] + \"/\" + os.environ['CUSTOMER_NAME'])\n",
    "data = loader.load_and_split(RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9950650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1975 chunks in the documents\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(data)} chunks in the documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b15dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='2-16 Instruments and controlsIf an ABS malfunction occurs, the anti-\\nlock function is turned off. The brake\\nsystem then operates normally, but with-out anti-lock assistance. (See “Brake sys-\\ntem” (P.5-152).)\\nApproaching Vehicle Sound\\nfor Pedestrians (VSP) OFF indicator\\nlight\\nIf the VSP OFF indicator illuminates while\\nthe VSP system is ON, it will may indicatethe VSP is not functioning properly. Have\\nthe VSP system checked. It is recom-\\nmended that you visit a NISSAN certifiedARIYA dealer.\\nSee “Approaching Vehicle Sound for Pe-\\ndestrians (VSP) system” (P.EV-20).\\nAutomaticEmergency Braking\\n(AEB) system OFF warning light\\nWhen the power switch is in the ON\\nposition, the Automatic Emergency Brak-ing (AEB) system OFF warning light illu-\\nminates. After starting the EV system, the\\nwarning light turns off.\\nThis light illuminates when the Automatic\\nEmergency Braking (AEB) with Pedestrian\\nDetection system is set to OFF on the\\nvehicle information display.' metadata={'source': '/mnt/data/Local-RAG-Customised/nissan/2023-nissan-ariya-owner-manual.pdf', 'page': 169}\n"
     ]
    }
   ],
   "source": [
    "# Pick a sample page\n",
    "print(data[random.randint(0, len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98374bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975 1975\n"
     ]
    }
   ],
   "source": [
    "# Split the data into pages\n",
    "metadatas = []\n",
    "texts = []\n",
    "for row in data:\n",
    "  metadatas.append(row.metadata)\n",
    "  texts.append(row.page_content)\n",
    "print(len(metadatas),len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5584f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|██████████| 1.52k/1.52k [00:00<00:00, 213kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 29.6kB/s]\n",
      "README.md: 100%|██████████| 90.8k/90.8k [00:00<00:00, 1.35MB/s]\n",
      "config.json: 100%|██████████| 684/684 [00:00<00:00, 395kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 124/124 [00:00<00:00, 71.8kB/s]\n",
      "model.safetensors: 100%|██████████| 133M/133M [00:00<00:00, 283MB/s] \n",
      "pytorch_model.bin: 100%|██████████| 134M/134M [00:00<00:00, 393MB/s] \n",
      "sentence_bert_config.json: 100%|██████████| 52.0/52.0 [00:00<00:00, 7.82kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 71.3kB/s]\n",
      "tokenizer.json: 100%|██████████| 711k/711k [00:00<00:00, 2.67MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 366/366 [00:00<00:00, 197kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 59.8MB/s]\n",
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 199kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the embedding model and cache it in our artifacts directory\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embedding_model_name = \"BAAI/bge-small-en\"\n",
    "os.environ['SENTENCE_TRANSFORMERS_HOME'] = '/mnt/artifacts/model_cache/'\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-small-en\",\n",
    "                                      model_kwargs=model_kwargs,\n",
    "                                      encode_kwargs=encode_kwargs\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c253c",
   "metadata": {},
   "source": [
    "### Initialise the Vector Store\n",
    "Now we can create the collection in the Qdrant Vector Store database.\n",
    "\n",
    "**Note: This step takes several minutes!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6c93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the embeddings to disk in our artifacts directory\n",
    "doc_store = Qdrant.from_texts(texts,\n",
    "                              metadatas=metadatas,\n",
    "                              embedding=embeddings,\n",
    "                              path=\"/mnt/artifacts/local_qdrant/\",\n",
    "                              prefer_grpc=True,\n",
    "                              collection_name=\"nissan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab5208",
   "metadata": {},
   "source": [
    "## Initialise the Model\n",
    "\n",
    "Now that we have the Vector Store and the Embedding Model we need to get the Foundation Model that we will be using.\n",
    "In this case we are leveraging the open source Llama2 model Llama-2-7b-chat-hf. In contrast to third party services like OpenAI this open source model allows you to download the model into your cloud and run it entirely in your enterprises ecosystem meaning you have tighter controls over security and governance.\n",
    "\n",
    "We will:\n",
    "1. Set up the prompt for this use case\n",
    "2. Configure bitsandbytes for the quantisation we need\n",
    "3. Download, configure and save the Llama2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f5756",
   "metadata": {},
   "source": [
    "1. Set up the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bed806e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup the prompt template to use for the QA bot\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question enclosed within  3 backticks at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Please provide an answer which is factually correct and based on the information retrieved from the vector store.\n",
    "Please also mention any quotes supporting the answer if any present in the context supplied within two double quotes \"\" .\n",
    "\n",
    "{context}\n",
    "\n",
    "QUESTION:```{question}```\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\",\"question\"])\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8804897",
   "metadata": {},
   "source": [
    "2. Configure bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a612f71c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.58s/it]\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Configure bitsandbytes\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733c81ef",
   "metadata": {},
   "source": [
    "3. Download and configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=\"/mnt/artifacts/model_cache/\",\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec62b33",
   "metadata": {},
   "source": [
    "## Putting it all together!\n",
    "\n",
    "Now we have our Vector Database with our documents in it and our configured model we can creat our RAG QA chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89c4a116",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m      3\u001b[0m rag_llm \u001b[38;5;241m=\u001b[39m HuggingFacePipeline(pipeline\u001b[38;5;241m=\u001b[39mpipe)\n\u001b[1;32m      5\u001b[0m qa_chain \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(llm\u001b[38;5;241m=\u001b[39mrag_llm,\n\u001b[1;32m      6\u001b[0m                                        chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                        chain_type_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: PROMPT},\n\u001b[0;32m----> 8\u001b[0m                                        retriever\u001b[38;5;241m=\u001b[39m\u001b[43mdoc_store\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m}),\n\u001b[1;32m      9\u001b[0m                                        return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m                                       )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_store' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup the QA chain\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=200)\n",
    "rag_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "    \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=rag_llm,\n",
    "                                       chain_type=\"stuff\",\n",
    "                                       chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                                       retriever=doc_store.as_retriever(search_kwargs={\"k\": 5}),\n",
    "                                       return_source_documents=True\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c8af5e",
   "metadata": {},
   "source": [
    "Now we can test our model!\n",
    "\n",
    "Run the following cell and ask a question based on the documents you have added to the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa6c83ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide your question here : how do I change the key fob battery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'how do I change the key fob battery', 'result': 'The process for replacing the Intelligent Key battery in a Nissan Ariya is outlined in the service manual. To change the battery, follow these steps:\\n\\n1. Remove the mechanical key from the Intelligent Key.\\n2. Insert a small screwdriver into the slit (on the right and left sides) and twist it to separate the upper part from the lower part of the Intelligent Key.\\n3. Remove the old battery and replace it with a new CR2032 battery. Make sure the + side of the new battery faces the bottom of the case.\\n4. Align the tips of the upper and lower parts and push them together until it is securely closed.\\n5. Operate the buttons to check its operation.\\n\\nIt is recommended to visit a Nissan certified dealer for this service, as they have the proper training and equipment to perform the replacement correctly.\\n\\nNote: The', 'source_documents': [Document(page_content='Replace the battery in the Intelligent Key\\nas follows:\\n1. Remove the mechanical key from the\\nIntelligent Key.\\n2. Insert a small screwdriver into the slit\\n(on the right and left sides) and twist it\\nto separate the upper part from the\\nDo-it-yourself 8-13INTELLIGENT KEY BATTERY REPLACEMENT', metadata={'source': '/mnt/data/Local-RAG-Customised/nissan/2023-nissan-ariya-owner-manual.pdf', 'page': 560}), Document(page_content='.When the vehicle is parked near a\\nparking meter.\\nIn such cases, correct the operating\\nconditions before using the Intelligent\\nKey function or use the mechanical key.\\nAlthough the life of the battery varies\\ndepending on the operating conditions,\\nthe battery’s life is approximately 2 years.\\nIf the battery is discharged, replace it with\\na new one.\\nWhen the Intelligent Key battery is low, an\\nindicator illuminates in the vehicle infor-\\nmation display. (See “4. Key Battery Lowwarning” (P.2-34).)\\nSince the Intelligent Key is continuously\\nreceiving radio waves, if the key is leftnear equipment which transmits strongradio waves, such as signals from a TV\\nand personal computer, the battery life\\nmay become shorter.\\nFor information regarding replacement of\\na battery, see “Intelligent Key battery\\nreplacement” (P.8-13).\\nAs many as 4 Intelligent Keys can be\\nregistered and used with one vehicle. For\\ninformation about the purchase and use\\nof additional Intelligent Keys, it is recom-', metadata={'source': '/mnt/data/Local-RAG-Customised/nissan/2023-nissan-ariya-owner-manual.pdf', 'page': 264}), Document(page_content='8-14 Do-it-yourselflower part. Use a cloth to protect the\\ncasing.\\n3. Replace the battery with a new one.\\nRecommended battery:\\nCR2032 or equivalent\\n.Do not touch the internal circuit\\nand electric terminals as doing so\\ncould cause a malfunction.\\n.Hold the battery by the edges.\\nHolding the battery across thecontactpointswillseriouslydeplete\\nthe storage capacity.\\n.Make sure that the +side faces the\\nbottom of the case.\\n WBI0015X\\n4. Align the tips of the upper and lower\\nparts, and then push them together\\nuntil it is securely closed.\\n5. Operate the buttons to check its\\noperation.\\nIf you need any assistance for replace-\\nment, it is recommended you visit a\\nNISSAN certified ARIYA dealer for this\\nservice.\\nFCC Notice:For USA:\\nFCC ID : KR5TXPZ1\\nFCC ID : KR5HFM401FCC ID : KR5HFM403\\nThis device complies with Part 15 of theFCC Rules. Operation is subject to the\\nfollowing two conditions: (1) This device\\nmay not cause harmful interference,and (2) this device must accept any', metadata={'source': '/mnt/data/Local-RAG-Customised/nissan/2023-nissan-ariya-owner-manual.pdf', 'page': 561}), Document(page_content='CH-10 Chargingvehicle.\\nTo start normal charge:\\n1. Push the P (Park) position switch to\\nplace the vehicle in the P (Park) posi-\\ntion and apply the parking brake.\\n2. When charging the Li-ion battery,\\nplace the power switch in the OFF\\nposition.\\n3. Open the charge port lid and charge\\nport cap. For additional information,\\nsee “Charge port lid” (P.3-27) and\\n“Charge port cap” (P.3-27).\\nWBT0114X\\n4. Connect the charge connector to the\\ncharge port. If it is connected nor-\\nmally, a beep will sound once.\\n5. If charging has started, a beep will\\nsound twice and the charging statusindicator light will operate. For addi-tional information, see “Charging sta-\\ntus indicator light” (P.CH-38).\\nWBT0115X\\nTo stop normal charge:\\n1. Ensurethatthechargeconnectorlock\\nis not engaged. For additional infor-\\nmation, see “Charge connector lock”\\n(P.CH-33).\\n2. Press the button on the charge con-\\nnector, release the lock and remove\\nthecharge connectorfromthe charge\\nport and properly store it.\\nNOTE:', metadata={'source': '/mnt/data/Local-RAG-Customised/nissan/2023-nissan-ariya-owner-manual.pdf', 'page': 49}), Document(page_content='5-16 Starting and driving\\nWBF0089X\\nINTELLIGENT KEY BATTERY DIS-\\nCHARGE\\nIf the battery of the Intelligent Key is\\ndischarged, or environmental conditions\\ninterfere with the Intelligent Key opera-\\ntion, start the EV (Electric Vehicle) systemin the READY to drive mode according tothe following procedure:\\n1. Push the park button to shift to the P\\n(Park) position.\\n2. Firmly apply the foot brake.3. Push the power switch.\\n4. Touch the power switch with the\\nIntelligent Key as illustrated. (A chime\\nwill sound.)5. Push the power switch while depres-\\nsing the brake pedal within 10 sec-\\nonds after the chime sounds. Thepower switch position changes to\\nREADY to drive.\\nAfterstep3isperformed,whenthepower\\nswitch is pushed without depressing the\\nbrake pedal, the power switch position\\nwill change to ON.\\nNOTE:\\n.When the power switch is pushed to\\nthe ON position or READY to drive\\nposition by the above procedures,\\nthe “Key Battery Low” warning may\\nappear (on the vehicle information', metadata={'source': '/mnt/data/Local-RAG-Customised/nissan/2023-nissan-ariya-owner-manual.pdf', 'page': 355})]}\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "user_question = input(\"Please provide your question here :\")\n",
    "result = qa_chain(user_question)\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce8ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
